{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Glaucoma_TransferLearning.ipynb adlı dosyanın kopyası","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPM/a3bSTamgkuJ2RV8zBdC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"jCztIGbArTGX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1592985252244,"user_tz":-180,"elapsed":27154,"user":{"displayName":"Murat UÇAR","photoUrl":"","userId":"15135126161682441538"}},"outputId":"2369eaab-75e4-4f17-deb9-3e3de5aaf16e"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wVpauYRFrrWp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":428},"executionInfo":{"status":"ok","timestamp":1592985268483,"user_tz":-180,"elapsed":12578,"user":{"displayName":"Murat UÇAR","photoUrl":"","userId":"15135126161682441538"}},"outputId":"0ce045ef-2011-4a82-83f0-37181025c77c"},"source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","!pip install -U efficientnet\n","\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import scipy.io as sio\n","import os\n","import sys\n","\n","from keras.applications.resnet50 import ResNet50\n","from keras.models import Model\n","from keras.layers import Dense, GlobalAveragePooling2D,Flatten\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import EarlyStopping\n","from keras.layers import Input\n","from keras import callbacks,optimizers\n","from keras.callbacks import LearningRateScheduler\n","\n","from sklearn.metrics import classification_report, confusion_matrix\n","import pickle\n","from sklearn.model_selection import train_test_split\n","from keras.callbacks import ModelCheckpoint\n","import os\n","from shutil import copyfile\n","import cv2\n","from keras.preprocessing import image\n","from keras.preprocessing.image import array_to_img, img_to_array, load_img,save_img\n","import numpy as np\n","from keras.utils import to_categorical\n","from keras.models import load_model\n","import math\n","\n","mainFolder = \"/gdrive/My Drive/glaucoma\"\n","os.chdir(mainFolder)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","1.15.2\n","Collecting efficientnet\n","  Downloading https://files.pythonhosted.org/packages/28/91/67848a143b54c331605bfba5fd31cf4e9db13d2e429d103fe807acc3bcf4/efficientnet-1.1.0-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from efficientnet) (1.0.8)\n","Requirement already satisfied, skipping upgrade: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet) (0.16.2)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n","Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.1.1)\n","Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4)\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.4.1)\n","Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (7.0.0)\n","Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4.1)\n","Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (3.2.2)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.12.0)\n","Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.0)\n","Installing collected packages: efficientnet\n","Successfully installed efficientnet-1.1.0\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vHYgpCRM-TkH","colab_type":"code","colab":{}},"source":["imageFolder = \"Data\"\n","subFolders = [\"non_glaucoma\",\"suspicious_glaucoma\"]\n","classes = {'non_glaucoma':0, 'suspicious_glaucoma':1}\n","\n","fileList = []\n","Y = []\n","\n","for index,folder in enumerate(subFolders):\n","    files = os.listdir(os.path.join(imageFolder,folder))\n","    for file in files:\n","      fileList.append(os.path.join(folder,file))\n","    for i in range(len(files)):\n","      Y.append(classes[os.path.split(folder)[-1]])\n","\n","Y = np.array(Y)\n","fileList = np.array(fileList)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zP5zv6IK_IIK","colab_type":"code","colab":{}},"source":["def FileRead(imageFolder,fileList,imageSize):\n","    X = []\n","    for file in fileList:\n","      img = image.load_img(os.path.join(imageFolder,file), target_size=imageSize)\n","      img = image.img_to_array(img)\n","      X.append(img)\n","    return np.array(X)\n","\n","trainFiles,testFiles,y_train,y_test = train_test_split(fileList,to_categorical(Y), test_size=0.20, random_state=1,stratify=to_categorical(Y))\n","trainFiles,validationFiles,y_train,y_val = train_test_split(trainFiles,y_train, test_size=0.10, random_state=1,stratify=y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8jzqIInlelOj","colab_type":"text"},"source":["# VGG16"]},{"cell_type":"code","metadata":{"id":"bIy5hH7qtaNd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592992886087,"user_tz":-180,"elapsed":7067850,"user":{"displayName":"Murat UÇAR","photoUrl":"","userId":"15135126161682441538"}},"outputId":"66eddb94-a802-467b-8f2f-dfee7f4be950"},"source":["\n","from keras.applications.vgg16  import VGG16\n","from keras.applications.vgg16 import preprocess_input\n","\n","x_train = preprocess_input(FileRead(imageFolder,trainFiles,(224,224)))\n","x_test = preprocess_input(FileRead(imageFolder,testFiles,(224,224)))\n","x_val = preprocess_input(FileRead(imageFolder,validationFiles,(224,224)))\n","\n","resultFolder = \"Results/VGG16\"\n","\n","checkpoint = ModelCheckpoint(os.path.join(resultFolder,\"model.hdf5\"), monitor='val_loss', verbose=1,\n","    save_best_only=True, mode='auto', period=1)\n","\n","base_model = VGG16(weights='imagenet',include_top=False)\n","\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","predictions = Dense(2, activation='softmax')(x)\n","\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","for layer in model.layers:\n","    layer.trainable = True  \n","\n","adam = optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, amsgrad=False)\n","model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","history = model.fit(x_train,y_train,\n","                    batch_size=64,\n","                    validation_data=(x_val, y_val),\n","                    verbose=1,epochs=50,\n","                    callbacks=[checkpoint]\n","                    )\n","\n","model = load_model(os.path.join(resultFolder,\"model.hdf5\"))\n","y_head = model.predict(x_test)\n","clfReport = classification_report(np.argmax(y_test,axis=1),np.argmax(y_head,axis=1) ,digits=4)\n","cnfMatris = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_head,axis=1))\n","print(cnfMatris)\n","print(clfReport)\n","\n","np.save(os.path.join(resultFolder,\"confMatris.npy\"),cnfMatris)\n","with open(os.path.join(resultFolder,'trainHistoryDict'), 'wb') as file_pi:\n","        pickle.dump(history.history, file_pi)\n","with open(os.path.join(resultFolder,'clfReport'), 'wb') as file_pi:\n","        pickle.dump(clfReport, file_pi)        \n","np.save(os.path.join(resultFolder,\"preds.npy\"),y_head)\n","np.save(os.path.join(resultFolder,\"y_test.npy\"),y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 5s 0us/step\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 3494 samples, validate on 389 samples\n","Epoch 1/50\n","3494/3494 [==============================] - 78s 22ms/step - loss: 0.5476 - accuracy: 0.7467 - val_loss: 0.3537 - val_accuracy: 0.8329\n","\n","Epoch 00001: val_loss improved from inf to 0.35367, saving model to Results/VGG16/model.hdf5\n","Epoch 2/50\n","3494/3494 [==============================] - 61s 18ms/step - loss: 0.2857 - accuracy: 0.8729 - val_loss: 0.2169 - val_accuracy: 0.9049\n","\n","Epoch 00002: val_loss improved from 0.35367 to 0.21695, saving model to Results/VGG16/model.hdf5\n","Epoch 3/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 0.1524 - accuracy: 0.9405 - val_loss: 0.1833 - val_accuracy: 0.9332\n","\n","Epoch 00003: val_loss improved from 0.21695 to 0.18326, saving model to Results/VGG16/model.hdf5\n","Epoch 4/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 0.1147 - accuracy: 0.9554 - val_loss: 0.1352 - val_accuracy: 0.9563\n","\n","Epoch 00004: val_loss improved from 0.18326 to 0.13517, saving model to Results/VGG16/model.hdf5\n","Epoch 5/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 0.0649 - accuracy: 0.9782 - val_loss: 0.1056 - val_accuracy: 0.9537\n","\n","Epoch 00005: val_loss improved from 0.13517 to 0.10563, saving model to Results/VGG16/model.hdf5\n","Epoch 6/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 0.0799 - accuracy: 0.9697 - val_loss: 0.1693 - val_accuracy: 0.9460\n","\n","Epoch 00006: val_loss did not improve from 0.10563\n","Epoch 7/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 0.0367 - accuracy: 0.9894 - val_loss: 0.1162 - val_accuracy: 0.9589\n","\n","Epoch 00007: val_loss did not improve from 0.10563\n","Epoch 8/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 0.0255 - accuracy: 0.9906 - val_loss: 0.1339 - val_accuracy: 0.9640\n","\n","Epoch 00008: val_loss did not improve from 0.10563\n","Epoch 9/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0969 - val_accuracy: 0.9769\n","\n","Epoch 00009: val_loss improved from 0.10563 to 0.09692, saving model to Results/VGG16/model.hdf5\n","Epoch 10/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 0.0242 - accuracy: 0.9900 - val_loss: 0.1048 - val_accuracy: 0.9717\n","\n","Epoch 00010: val_loss did not improve from 0.09692\n","Epoch 11/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 0.0513 - accuracy: 0.9808 - val_loss: 0.0759 - val_accuracy: 0.9717\n","\n","Epoch 00011: val_loss improved from 0.09692 to 0.07586, saving model to Results/VGG16/model.hdf5\n","Epoch 12/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 0.0151 - accuracy: 0.9946 - val_loss: 0.0785 - val_accuracy: 0.9666\n","\n","Epoch 00012: val_loss did not improve from 0.07586\n","Epoch 13/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.1093 - val_accuracy: 0.9640\n","\n","Epoch 00013: val_loss did not improve from 0.07586\n","Epoch 14/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 7.8739e-04 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9794\n","\n","Epoch 00014: val_loss did not improve from 0.07586\n","Epoch 15/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 1.8764e-04 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9794\n","\n","Epoch 00015: val_loss did not improve from 0.07586\n","Epoch 16/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 1.0226e-04 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9769\n","\n","Epoch 00016: val_loss did not improve from 0.07586\n","Epoch 17/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 7.7387e-05 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9794\n","\n","Epoch 00017: val_loss did not improve from 0.07586\n","Epoch 18/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 6.2495e-05 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9820\n","\n","Epoch 00018: val_loss did not improve from 0.07586\n","Epoch 19/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 5.1073e-05 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9794\n","\n","Epoch 00019: val_loss did not improve from 0.07586\n","Epoch 20/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 4.3146e-05 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9820\n","\n","Epoch 00020: val_loss did not improve from 0.07586\n","Epoch 21/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 3.7318e-05 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9820\n","\n","Epoch 00021: val_loss did not improve from 0.07586\n","Epoch 22/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 3.1860e-05 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9794\n","\n","Epoch 00022: val_loss did not improve from 0.07586\n","Epoch 23/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 2.7977e-05 - accuracy: 1.0000 - val_loss: 0.1125 - val_accuracy: 0.9820\n","\n","Epoch 00023: val_loss did not improve from 0.07586\n","Epoch 24/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 2.4377e-05 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9820\n","\n","Epoch 00024: val_loss did not improve from 0.07586\n","Epoch 25/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 2.1378e-05 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9794\n","\n","Epoch 00025: val_loss did not improve from 0.07586\n","Epoch 26/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 1.8612e-05 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9794\n","\n","Epoch 00026: val_loss did not improve from 0.07586\n","Epoch 27/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 1.6616e-05 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9794\n","\n","Epoch 00027: val_loss did not improve from 0.07586\n","Epoch 28/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 1.4698e-05 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9794\n","\n","Epoch 00028: val_loss did not improve from 0.07586\n","Epoch 29/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 1.3264e-05 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9794\n","\n","Epoch 00029: val_loss did not improve from 0.07586\n","Epoch 30/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 1.1925e-05 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9794\n","\n","Epoch 00030: val_loss did not improve from 0.07586\n","Epoch 31/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 1.0799e-05 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9820\n","\n","Epoch 00031: val_loss did not improve from 0.07586\n","Epoch 32/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 9.8148e-06 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9820\n","\n","Epoch 00032: val_loss did not improve from 0.07586\n","Epoch 33/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 9.0237e-06 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9820\n","\n","Epoch 00033: val_loss did not improve from 0.07586\n","Epoch 34/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 8.3236e-06 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9794\n","\n","Epoch 00034: val_loss did not improve from 0.07586\n","Epoch 35/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 7.6266e-06 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9820\n","\n","Epoch 00035: val_loss did not improve from 0.07586\n","Epoch 36/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 7.0168e-06 - accuracy: 1.0000 - val_loss: 0.1297 - val_accuracy: 0.9820\n","\n","Epoch 00036: val_loss did not improve from 0.07586\n","Epoch 37/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 6.4697e-06 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9820\n","\n","Epoch 00037: val_loss did not improve from 0.07586\n","Epoch 38/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 6.0463e-06 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9794\n","\n","Epoch 00038: val_loss did not improve from 0.07586\n","Epoch 39/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 5.7186e-06 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9820\n","\n","Epoch 00039: val_loss did not improve from 0.07586\n","Epoch 40/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 5.2044e-06 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9820\n","\n","Epoch 00040: val_loss did not improve from 0.07586\n","Epoch 41/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 4.8272e-06 - accuracy: 1.0000 - val_loss: 0.1332 - val_accuracy: 0.9820\n","\n","Epoch 00041: val_loss did not improve from 0.07586\n","Epoch 42/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 4.5879e-06 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9820\n","\n","Epoch 00042: val_loss did not improve from 0.07586\n","Epoch 43/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 4.2736e-06 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9820\n","\n","Epoch 00043: val_loss did not improve from 0.07586\n","Epoch 44/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 3.9899e-06 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9820\n","\n","Epoch 00044: val_loss did not improve from 0.07586\n","Epoch 45/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 3.7542e-06 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9820\n","\n","Epoch 00045: val_loss did not improve from 0.07586\n","Epoch 46/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 3.5307e-06 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9820\n","\n","Epoch 00046: val_loss did not improve from 0.07586\n","Epoch 47/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 3.3097e-06 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9820\n","\n","Epoch 00047: val_loss did not improve from 0.07586\n","Epoch 48/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 3.1122e-06 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9820\n","\n","Epoch 00048: val_loss did not improve from 0.07586\n","Epoch 49/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 2.9216e-06 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9820\n","\n","Epoch 00049: val_loss did not improve from 0.07586\n","Epoch 50/50\n","3494/3494 [==============================] - 62s 18ms/step - loss: 2.7859e-06 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9820\n","\n","Epoch 00050: val_loss did not improve from 0.07586\n","[[604  25]\n"," [ 14 328]]\n","              precision    recall  f1-score   support\n","\n","           0     0.9773    0.9603    0.9687       629\n","           1     0.9292    0.9591    0.9439       342\n","\n","    accuracy                         0.9598       971\n","   macro avg     0.9533    0.9597    0.9563       971\n","weighted avg     0.9604    0.9598    0.9600       971\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"V6up7KWQeq0f","colab_type":"text"},"source":["# EfficientNET"]},{"cell_type":"code","metadata":{"id":"iH_eJ8CNLUOX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592996241530,"user_tz":-180,"elapsed":2995837,"user":{"displayName":"Murat UÇAR","photoUrl":"","userId":"15135126161682441538"}},"outputId":"cc9ca4d2-a2df-4865-ee8d-77ab0aefc541"},"source":["import efficientnet.keras as efn \n","\n","os.chdir(mainFolder)\n","\n","x_train = efn.preprocess_input(FileRead(imageFolder,trainFiles,(224,224)))\n","x_test = efn.preprocess_input(FileRead(imageFolder,testFiles,(224,224)))\n","x_val = efn.preprocess_input(FileRead(imageFolder,validationFiles,(224,224)))\n","\n","resultFolder =\"Results/EfficientNet\" \n","\n","checkpoint = ModelCheckpoint(os.path.join(resultFolder,\"model.hdf5\"), monitor='val_loss', verbose=1,\n","    save_best_only=True, mode='auto', period=1)\n","\n","base_model = efn.EfficientNetB0(weights='imagenet',include_top=False)\n","\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","predictions = Dense(2, activation='softmax')(x)\n","\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","for layer in model.layers:\n","    layer.trainable = True  \n","\n","adam = optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, amsgrad=False)\n","model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","history = model.fit(x_train,y_train,\n","                    batch_size=32,\n","                    validation_data=(x_val, y_val),\n","                     verbose=1,epochs=50,\n","                    callbacks=[checkpoint]\n","                    )\n","\n","model = load_model(os.path.join(resultFolder,\"model.hdf5\"))\n","y_head = model.predict(x_test)\n","clfReport = classification_report(np.argmax(y_test,axis=1),np.argmax(y_head,axis=1) ,digits=4)\n","cnfMatris = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_head,axis=1))\n","print(cnfMatris)\n","print(clfReport)\n","\n","np.save(os.path.join(resultFolder,\"confMatris.npy\"),cnfMatris)\n","with open(os.path.join(resultFolder,'trainHistoryDict'), 'wb') as file_pi:\n","        pickle.dump(history.history, file_pi)\n","with open(os.path.join(resultFolder,'clfReport'), 'wb') as file_pi:\n","        pickle.dump(clfReport, file_pi)        \n","np.save(os.path.join(resultFolder,\"preds.npy\"),y_head)\n","np.save(os.path.join(resultFolder,\"y_test.npy\"),y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n","16809984/16804768 [==============================] - 3s 0us/step\n","Train on 3494 samples, validate on 389 samples\n","Epoch 1/50\n","3494/3494 [==============================] - 67s 19ms/step - loss: 0.3902 - accuracy: 0.8246 - val_loss: 0.3359 - val_accuracy: 0.8509\n","\n","Epoch 00001: val_loss improved from inf to 0.33590, saving model to Results/EfficientNet/model.hdf5\n","Epoch 2/50\n","3494/3494 [==============================] - 56s 16ms/step - loss: 0.1924 - accuracy: 0.9305 - val_loss: 0.2241 - val_accuracy: 0.9203\n","\n","Epoch 00002: val_loss improved from 0.33590 to 0.22414, saving model to Results/EfficientNet/model.hdf5\n","Epoch 3/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.1234 - accuracy: 0.9559 - val_loss: 0.1654 - val_accuracy: 0.9434\n","\n","Epoch 00003: val_loss improved from 0.22414 to 0.16539, saving model to Results/EfficientNet/model.hdf5\n","Epoch 4/50\n","3494/3494 [==============================] - 56s 16ms/step - loss: 0.0796 - accuracy: 0.9720 - val_loss: 0.1468 - val_accuracy: 0.9460\n","\n","Epoch 00004: val_loss improved from 0.16539 to 0.14683, saving model to Results/EfficientNet/model.hdf5\n","Epoch 5/50\n","3494/3494 [==============================] - 56s 16ms/step - loss: 0.0463 - accuracy: 0.9865 - val_loss: 0.1237 - val_accuracy: 0.9512\n","\n","Epoch 00005: val_loss improved from 0.14683 to 0.12373, saving model to Results/EfficientNet/model.hdf5\n","Epoch 6/50\n","3494/3494 [==============================] - 56s 16ms/step - loss: 0.0481 - accuracy: 0.9840 - val_loss: 0.0977 - val_accuracy: 0.9640\n","\n","Epoch 00006: val_loss improved from 0.12373 to 0.09768, saving model to Results/EfficientNet/model.hdf5\n","Epoch 7/50\n","3494/3494 [==============================] - 56s 16ms/step - loss: 0.0350 - accuracy: 0.9891 - val_loss: 0.0987 - val_accuracy: 0.9640\n","\n","Epoch 00007: val_loss did not improve from 0.09768\n","Epoch 8/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0283 - accuracy: 0.9917 - val_loss: 0.1048 - val_accuracy: 0.9666\n","\n","Epoch 00008: val_loss did not improve from 0.09768\n","Epoch 9/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0212 - accuracy: 0.9940 - val_loss: 0.1026 - val_accuracy: 0.9692\n","\n","Epoch 00009: val_loss did not improve from 0.09768\n","Epoch 10/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0187 - accuracy: 0.9951 - val_loss: 0.0855 - val_accuracy: 0.9692\n","\n","Epoch 00010: val_loss improved from 0.09768 to 0.08547, saving model to Results/EfficientNet/model.hdf5\n","Epoch 11/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0198 - accuracy: 0.9948 - val_loss: 0.1101 - val_accuracy: 0.9666\n","\n","Epoch 00011: val_loss did not improve from 0.08547\n","Epoch 12/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0141 - accuracy: 0.9948 - val_loss: 0.0939 - val_accuracy: 0.9666\n","\n","Epoch 00012: val_loss did not improve from 0.08547\n","Epoch 13/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.1110 - val_accuracy: 0.9666\n","\n","Epoch 00013: val_loss did not improve from 0.08547\n","Epoch 14/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.1054 - val_accuracy: 0.9743\n","\n","Epoch 00014: val_loss did not improve from 0.08547\n","Epoch 15/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 0.1123 - val_accuracy: 0.9640\n","\n","Epoch 00015: val_loss did not improve from 0.08547\n","Epoch 16/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.0988 - val_accuracy: 0.9666\n","\n","Epoch 00016: val_loss did not improve from 0.08547\n","Epoch 17/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0111 - accuracy: 0.9980 - val_loss: 0.1032 - val_accuracy: 0.9769\n","\n","Epoch 00017: val_loss did not improve from 0.08547\n","Epoch 18/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0970 - val_accuracy: 0.9769\n","\n","Epoch 00018: val_loss did not improve from 0.08547\n","Epoch 19/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.1210 - val_accuracy: 0.9769\n","\n","Epoch 00019: val_loss did not improve from 0.08547\n","Epoch 20/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.1098 - val_accuracy: 0.9743\n","\n","Epoch 00020: val_loss did not improve from 0.08547\n","Epoch 21/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0894 - val_accuracy: 0.9743\n","\n","Epoch 00021: val_loss did not improve from 0.08547\n","Epoch 22/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.1107 - val_accuracy: 0.9794\n","\n","Epoch 00022: val_loss did not improve from 0.08547\n","Epoch 23/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1422 - val_accuracy: 0.9666\n","\n","Epoch 00023: val_loss did not improve from 0.08547\n","Epoch 24/50\n","3494/3494 [==============================] - 56s 16ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.1394 - val_accuracy: 0.9666\n","\n","Epoch 00024: val_loss did not improve from 0.08547\n","Epoch 25/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.1264 - val_accuracy: 0.9666\n","\n","Epoch 00025: val_loss did not improve from 0.08547\n","Epoch 26/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.1243 - val_accuracy: 0.9717\n","\n","Epoch 00026: val_loss did not improve from 0.08547\n","Epoch 27/50\n","3494/3494 [==============================] - 56s 16ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.1291 - val_accuracy: 0.9717\n","\n","Epoch 00027: val_loss did not improve from 0.08547\n","Epoch 28/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.1231 - val_accuracy: 0.9717\n","\n","Epoch 00028: val_loss did not improve from 0.08547\n","Epoch 29/50\n","3494/3494 [==============================] - 56s 16ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1259 - val_accuracy: 0.9743\n","\n","Epoch 00029: val_loss did not improve from 0.08547\n","Epoch 30/50\n","3494/3494 [==============================] - 56s 16ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.1134 - val_accuracy: 0.9769\n","\n","Epoch 00030: val_loss did not improve from 0.08547\n","Epoch 31/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.1242 - val_accuracy: 0.9717\n","\n","Epoch 00031: val_loss did not improve from 0.08547\n","Epoch 32/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1094 - val_accuracy: 0.9743\n","\n","Epoch 00032: val_loss did not improve from 0.08547\n","Epoch 33/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.1086 - val_accuracy: 0.9743\n","\n","Epoch 00033: val_loss did not improve from 0.08547\n","Epoch 34/50\n","3494/3494 [==============================] - 56s 16ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.1154 - val_accuracy: 0.9743\n","\n","Epoch 00034: val_loss did not improve from 0.08547\n","Epoch 35/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0032 - accuracy: 0.9986 - val_loss: 0.1206 - val_accuracy: 0.9743\n","\n","Epoch 00035: val_loss did not improve from 0.08547\n","Epoch 36/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.1249 - val_accuracy: 0.9769\n","\n","Epoch 00036: val_loss did not improve from 0.08547\n","Epoch 37/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1440 - val_accuracy: 0.9769\n","\n","Epoch 00037: val_loss did not improve from 0.08547\n","Epoch 38/50\n","3494/3494 [==============================] - 56s 16ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.1764 - val_accuracy: 0.9692\n","\n","Epoch 00038: val_loss did not improve from 0.08547\n","Epoch 39/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1405 - val_accuracy: 0.9717\n","\n","Epoch 00039: val_loss did not improve from 0.08547\n","Epoch 40/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.1607 - val_accuracy: 0.9666\n","\n","Epoch 00040: val_loss did not improve from 0.08547\n","Epoch 41/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.1473 - val_accuracy: 0.9666\n","\n","Epoch 00041: val_loss did not improve from 0.08547\n","Epoch 42/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.1084 - val_accuracy: 0.9692\n","\n","Epoch 00042: val_loss did not improve from 0.08547\n","Epoch 43/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1056 - val_accuracy: 0.9743\n","\n","Epoch 00043: val_loss did not improve from 0.08547\n","Epoch 44/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1035 - val_accuracy: 0.9769\n","\n","Epoch 00044: val_loss did not improve from 0.08547\n","Epoch 45/50\n","3494/3494 [==============================] - 56s 16ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.1251 - val_accuracy: 0.9769\n","\n","Epoch 00045: val_loss did not improve from 0.08547\n","Epoch 46/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0062 - accuracy: 0.9974 - val_loss: 0.1490 - val_accuracy: 0.9717\n","\n","Epoch 00046: val_loss did not improve from 0.08547\n","Epoch 47/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.1698 - val_accuracy: 0.9717\n","\n","Epoch 00047: val_loss did not improve from 0.08547\n","Epoch 48/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 0.1560 - val_accuracy: 0.9717\n","\n","Epoch 00048: val_loss did not improve from 0.08547\n","Epoch 49/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1271 - val_accuracy: 0.9692\n","\n","Epoch 00049: val_loss did not improve from 0.08547\n","Epoch 50/50\n","3494/3494 [==============================] - 55s 16ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.1445 - val_accuracy: 0.9717\n","\n","Epoch 00050: val_loss did not improve from 0.08547\n","[[609  20]\n"," [ 25 317]]\n","              precision    recall  f1-score   support\n","\n","           0     0.9606    0.9682    0.9644       629\n","           1     0.9407    0.9269    0.9337       342\n","\n","    accuracy                         0.9537       971\n","   macro avg     0.9506    0.9476    0.9490       971\n","weighted avg     0.9536    0.9537    0.9536       971\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v-93PYXneo36","colab_type":"text"},"source":["# denseNET"]},{"cell_type":"code","metadata":{"id":"5NIJEKN4sxJp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592951746818,"user_tz":-180,"elapsed":4293849,"user":{"displayName":"Murat UÇAR","photoUrl":"","userId":"15135126161682441538"}},"outputId":"bca56b59-dd36-48b9-8ea9-8bfe1a6defa1"},"source":["from keras.applications.densenet  import DenseNet121\n","from keras.applications.densenet import preprocess_input\n","\n","os.chdir(mainFolder)\n","\n","x_train = preprocess_input(FileRead(imageFolder,trainFiles,(224,224)))\n","x_test = preprocess_input(FileRead(imageFolder,testFiles,(224,224)))\n","x_val = preprocess_input(FileRead(imageFolder,validationFiles,(224,224)))\n","\n","resultFolder =\"Results/DenseNET\" \n","\n","\n","checkpoint = ModelCheckpoint(os.path.join(resultFolder,\"model.hdf5\"), monitor='val_loss', verbose=1,\n","    save_best_only=True, mode='auto', period=1)\n","\n","base_model = DenseNet121(weights='imagenet',include_top=False)\n","\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","predictions = Dense(2, activation='softmax')(x)\n","\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","for layer in model.layers:\n","    layer.trainable = True  \n","\n","adam = optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, amsgrad=False)\n","model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","\n","\n","history = model.fit(x_train,y_train,\n","                    batch_size=16,\n","                    validation_data=(x_val, y_val),\n","                     verbose=1,epochs=50,\n","                    callbacks=[checkpoint]\n","                    )\n","\n","model = load_model(os.path.join(resultFolder,\"model.hdf5\"))\n","y_head = model.predict(x_test)\n","clfReport = classification_report(np.argmax(y_test,axis=1),np.argmax(y_head,axis=1) ,digits=4)\n","cnfMatris = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_head,axis=1))\n","print(cnfMatris)\n","print(clfReport)\n","\n","np.save(os.path.join(resultFolder,\"confMatris.npy\"),cnfMatris)\n","with open(os.path.join(resultFolder,'trainHistoryDict'), 'wb') as file_pi:\n","        pickle.dump(history.history, file_pi)\n","with open(os.path.join(resultFolder,'clfReport'), 'wb') as file_pi:\n","        pickle.dump(clfReport, file_pi)        \n","np.save(os.path.join(resultFolder,\"preds.npy\"),y_head)\n","np.save(os.path.join(resultFolder,\"y_test.npy\"),y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 3494 samples, validate on 389 samples\n","Epoch 1/50\n","3494/3494 [==============================] - 99s 28ms/step - loss: 0.2601 - accuracy: 0.8864 - val_loss: 0.2619 - val_accuracy: 0.8895\n","\n","Epoch 00001: val_loss improved from inf to 0.26192, saving model to Results/DenseNET/model.hdf5\n","Epoch 2/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0838 - accuracy: 0.9728 - val_loss: 0.1672 - val_accuracy: 0.9306\n","\n","Epoch 00002: val_loss improved from 0.26192 to 0.16720, saving model to Results/DenseNET/model.hdf5\n","Epoch 3/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0371 - accuracy: 0.9894 - val_loss: 0.1623 - val_accuracy: 0.9589\n","\n","Epoch 00003: val_loss improved from 0.16720 to 0.16233, saving model to Results/DenseNET/model.hdf5\n","Epoch 4/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 0.1019 - val_accuracy: 0.9589\n","\n","Epoch 00004: val_loss improved from 0.16233 to 0.10187, saving model to Results/DenseNET/model.hdf5\n","Epoch 5/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.1249 - val_accuracy: 0.9512\n","\n","Epoch 00005: val_loss did not improve from 0.10187\n","Epoch 6/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.1133 - val_accuracy: 0.9640\n","\n","Epoch 00006: val_loss did not improve from 0.10187\n","Epoch 7/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0236 - accuracy: 0.9906 - val_loss: 0.1066 - val_accuracy: 0.9692\n","\n","Epoch 00007: val_loss did not improve from 0.10187\n","Epoch 8/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0370 - accuracy: 0.9886 - val_loss: 0.1133 - val_accuracy: 0.9563\n","\n","Epoch 00008: val_loss did not improve from 0.10187\n","Epoch 9/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0151 - accuracy: 0.9960 - val_loss: 0.1071 - val_accuracy: 0.9537\n","\n","Epoch 00009: val_loss did not improve from 0.10187\n","Epoch 10/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.1313 - val_accuracy: 0.9640\n","\n","Epoch 00010: val_loss did not improve from 0.10187\n","Epoch 11/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0748 - val_accuracy: 0.9794\n","\n","Epoch 00011: val_loss improved from 0.10187 to 0.07478, saving model to Results/DenseNET/model.hdf5\n","Epoch 12/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1057 - val_accuracy: 0.9769\n","\n","Epoch 00012: val_loss did not improve from 0.07478\n","Epoch 13/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.1274 - val_accuracy: 0.9692\n","\n","Epoch 00013: val_loss did not improve from 0.07478\n","Epoch 14/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.1533 - val_accuracy: 0.9589\n","\n","Epoch 00014: val_loss did not improve from 0.07478\n","Epoch 15/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.1350 - val_accuracy: 0.9743\n","\n","Epoch 00015: val_loss did not improve from 0.07478\n","Epoch 16/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.1138 - val_accuracy: 0.9717\n","\n","Epoch 00016: val_loss did not improve from 0.07478\n","Epoch 17/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.1167 - val_accuracy: 0.9666\n","\n","Epoch 00017: val_loss did not improve from 0.07478\n","Epoch 18/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.1018 - val_accuracy: 0.9743\n","\n","Epoch 00018: val_loss did not improve from 0.07478\n","Epoch 19/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 9.8293e-04 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9717\n","\n","Epoch 00019: val_loss did not improve from 0.07478\n","Epoch 20/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1071 - val_accuracy: 0.9743\n","\n","Epoch 00020: val_loss did not improve from 0.07478\n","Epoch 21/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.1411 - val_accuracy: 0.9589\n","\n","Epoch 00021: val_loss did not improve from 0.07478\n","Epoch 22/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.2123 - val_accuracy: 0.9692\n","\n","Epoch 00022: val_loss did not improve from 0.07478\n","Epoch 23/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0144 - accuracy: 0.9937 - val_loss: 0.1599 - val_accuracy: 0.9692\n","\n","Epoch 00023: val_loss did not improve from 0.07478\n","Epoch 24/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0141 - accuracy: 0.9943 - val_loss: 0.1699 - val_accuracy: 0.9666\n","\n","Epoch 00024: val_loss did not improve from 0.07478\n","Epoch 25/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.1263 - val_accuracy: 0.9717\n","\n","Epoch 00025: val_loss did not improve from 0.07478\n","Epoch 26/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.1003 - val_accuracy: 0.9769\n","\n","Epoch 00026: val_loss did not improve from 0.07478\n","Epoch 27/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.2155 - val_accuracy: 0.9666\n","\n","Epoch 00027: val_loss did not improve from 0.07478\n","Epoch 28/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.1600 - val_accuracy: 0.9717\n","\n","Epoch 00028: val_loss did not improve from 0.07478\n","Epoch 29/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9692\n","\n","Epoch 00029: val_loss did not improve from 0.07478\n","Epoch 30/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 5.8552e-04 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9692\n","\n","Epoch 00030: val_loss did not improve from 0.07478\n","Epoch 31/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 5.6587e-04 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9717\n","\n","Epoch 00031: val_loss did not improve from 0.07478\n","Epoch 32/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0053 - accuracy: 0.9974 - val_loss: 0.2443 - val_accuracy: 0.9666\n","\n","Epoch 00032: val_loss did not improve from 0.07478\n","Epoch 33/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0251 - accuracy: 0.9911 - val_loss: 0.1760 - val_accuracy: 0.9589\n","\n","Epoch 00033: val_loss did not improve from 0.07478\n","Epoch 34/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0053 - accuracy: 0.9980 - val_loss: 0.2119 - val_accuracy: 0.9486\n","\n","Epoch 00034: val_loss did not improve from 0.07478\n","Epoch 35/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.1210 - val_accuracy: 0.9717\n","\n","Epoch 00035: val_loss did not improve from 0.07478\n","Epoch 36/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1197 - val_accuracy: 0.9717\n","\n","Epoch 00036: val_loss did not improve from 0.07478\n","Epoch 37/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 6.8573e-04 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9743\n","\n","Epoch 00037: val_loss did not improve from 0.07478\n","Epoch 38/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 3.0504e-04 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9717\n","\n","Epoch 00038: val_loss did not improve from 0.07478\n","Epoch 39/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 1.9055e-04 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9743\n","\n","Epoch 00039: val_loss did not improve from 0.07478\n","Epoch 40/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 1.6747e-04 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9743\n","\n","Epoch 00040: val_loss did not improve from 0.07478\n","Epoch 41/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 9.6444e-05 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9743\n","\n","Epoch 00041: val_loss did not improve from 0.07478\n","Epoch 42/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 8.1071e-05 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 0.9717\n","\n","Epoch 00042: val_loss did not improve from 0.07478\n","Epoch 43/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 5.3122e-05 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9692\n","\n","Epoch 00043: val_loss did not improve from 0.07478\n","Epoch 44/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 5.2285e-05 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 0.9743\n","\n","Epoch 00044: val_loss did not improve from 0.07478\n","Epoch 45/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0379 - accuracy: 0.9891 - val_loss: 0.1704 - val_accuracy: 0.9589\n","\n","Epoch 00045: val_loss did not improve from 0.07478\n","Epoch 46/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0238 - accuracy: 0.9943 - val_loss: 0.1586 - val_accuracy: 0.9692\n","\n","Epoch 00046: val_loss did not improve from 0.07478\n","Epoch 47/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0043 - accuracy: 0.9997 - val_loss: 0.1105 - val_accuracy: 0.9743\n","\n","Epoch 00047: val_loss did not improve from 0.07478\n","Epoch 48/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 5.7291e-04 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9743\n","\n","Epoch 00048: val_loss did not improve from 0.07478\n","Epoch 49/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 3.6403e-04 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 0.9794\n","\n","Epoch 00049: val_loss did not improve from 0.07478\n","Epoch 50/50\n","3494/3494 [==============================] - 75s 21ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.1489 - val_accuracy: 0.9589\n","\n","Epoch 00050: val_loss did not improve from 0.07478\n","[[607  22]\n"," [ 15 327]]\n","              precision    recall  f1-score   support\n","\n","           0     0.9759    0.9650    0.9704       629\n","           1     0.9370    0.9561    0.9465       342\n","\n","    accuracy                         0.9619       971\n","   macro avg     0.9564    0.9606    0.9584       971\n","weighted avg     0.9622    0.9619    0.9620       971\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cFA-eYmue2Cd","colab_type":"text"},"source":["# MobilNET"]},{"cell_type":"code","metadata":{"id":"NJDVFdytAY3W","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592953988243,"user_tz":-180,"elapsed":1692850,"user":{"displayName":"Murat UÇAR","photoUrl":"","userId":"15135126161682441538"}},"outputId":"56f7df44-c84d-4ca1-eafa-75a489b6dad3"},"source":["from keras.applications.mobilenet  import MobileNet\n","from keras.applications.mobilenet import preprocess_input\n","\n","os.chdir(mainFolder)\n","\n","x_train = preprocess_input(FileRead(imageFolder,trainFiles,(224,224)))\n","x_test = preprocess_input(FileRead(imageFolder,testFiles,(224,224)))\n","x_val = preprocess_input(FileRead(imageFolder,validationFiles,(224,224)))\n","\n","resultFolder =\"Results/MobilNET\" \n","\n","\n","checkpoint = ModelCheckpoint(os.path.join(resultFolder,\"model.hdf5\"), monitor='val_loss', verbose=1,\n","    save_best_only=True, mode='auto', period=1)\n","\n","base_model = MobileNet(weights='imagenet',include_top=False)\n","\n","# add a global spatial average pooling layer\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","#x = Dense(1024, activation='relu')(x)\n","predictions = Dense(2, activation='softmax')(x)\n","\n","# this is the model we will train\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","for layer in model.layers:\n","    layer.trainable = True  \n","\n","adam = optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, amsgrad=False)\n","model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","\n","history = model.fit(x_train,y_train,\n","                    batch_size=64,\n","                    validation_data=(x_val, y_val),\n","                     verbose=1,epochs=50,\n","                    callbacks=[checkpoint]\n","                    )\n","\n","model = load_model(os.path.join(resultFolder,\"model.hdf5\"))\n","y_head = model.predict(x_test)\n","clfReport = classification_report(np.argmax(y_test,axis=1),np.argmax(y_head,axis=1) ,digits=4)\n","cnfMatris = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_head,axis=1))\n","print(cnfMatris)\n","print(clfReport)\n","\n","np.save(os.path.join(resultFolder,\"confMatris.npy\"),cnfMatris)\n","with open(os.path.join(resultFolder,'trainHistoryDict'), 'wb') as file_pi:\n","        pickle.dump(history.history, file_pi)\n","with open(os.path.join(resultFolder,'clfReport'), 'wb') as file_pi:\n","        pickle.dump(clfReport, file_pi)        \n","np.save(os.path.join(resultFolder,\"preds.npy\"),y_head)\n","np.save(os.path.join(resultFolder,\"y_test.npy\"),y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","  warnings.warn('`input_shape` is undefined or non-square, '\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf_no_top.h5\n","17227776/17225924 [==============================] - 3s 0us/step\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 3494 samples, validate on 389 samples\n","Epoch 1/50\n","3494/3494 [==============================] - 42s 12ms/step - loss: 0.3541 - accuracy: 0.8366 - val_loss: 0.5041 - val_accuracy: 0.7506\n","\n","Epoch 00001: val_loss improved from inf to 0.50406, saving model to Results/MobilNET/model.hdf5\n","Epoch 2/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.1126 - accuracy: 0.9628 - val_loss: 0.7384 - val_accuracy: 0.6607\n","\n","Epoch 00002: val_loss did not improve from 0.50406\n","Epoch 3/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0521 - accuracy: 0.9926 - val_loss: 0.4851 - val_accuracy: 0.7918\n","\n","Epoch 00003: val_loss improved from 0.50406 to 0.48509, saving model to Results/MobilNET/model.hdf5\n","Epoch 4/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0272 - accuracy: 0.9991 - val_loss: 0.3895 - val_accuracy: 0.8458\n","\n","Epoch 00004: val_loss improved from 0.48509 to 0.38954, saving model to Results/MobilNET/model.hdf5\n","Epoch 5/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0138 - accuracy: 0.9997 - val_loss: 0.2592 - val_accuracy: 0.8997\n","\n","Epoch 00005: val_loss improved from 0.38954 to 0.25918, saving model to Results/MobilNET/model.hdf5\n","Epoch 6/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0135 - accuracy: 0.9994 - val_loss: 0.2983 - val_accuracy: 0.8895\n","\n","Epoch 00006: val_loss did not improve from 0.25918\n","Epoch 7/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9177\n","\n","Epoch 00007: val_loss improved from 0.25918 to 0.19662, saving model to Results/MobilNET/model.hdf5\n","Epoch 8/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.1866 - val_accuracy: 0.9203\n","\n","Epoch 00008: val_loss improved from 0.19662 to 0.18664, saving model to Results/MobilNET/model.hdf5\n","Epoch 9/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.1927 - val_accuracy: 0.9203\n","\n","Epoch 00009: val_loss did not improve from 0.18664\n","Epoch 10/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9254\n","\n","Epoch 00010: val_loss improved from 0.18664 to 0.16433, saving model to Results/MobilNET/model.hdf5\n","Epoch 11/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9486\n","\n","Epoch 00011: val_loss improved from 0.16433 to 0.13945, saving model to Results/MobilNET/model.hdf5\n","Epoch 12/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9512\n","\n","Epoch 00012: val_loss improved from 0.13945 to 0.13927, saving model to Results/MobilNET/model.hdf5\n","Epoch 13/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1300 - val_accuracy: 0.9537\n","\n","Epoch 00013: val_loss improved from 0.13927 to 0.13003, saving model to Results/MobilNET/model.hdf5\n","Epoch 14/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9512\n","\n","Epoch 00014: val_loss did not improve from 0.13003\n","Epoch 15/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9563\n","\n","Epoch 00015: val_loss improved from 0.13003 to 0.12577, saving model to Results/MobilNET/model.hdf5\n","Epoch 16/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9589\n","\n","Epoch 00016: val_loss did not improve from 0.12577\n","Epoch 17/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9563\n","\n","Epoch 00017: val_loss did not improve from 0.12577\n","Epoch 18/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9589\n","\n","Epoch 00018: val_loss did not improve from 0.12577\n","Epoch 19/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9589\n","\n","Epoch 00019: val_loss improved from 0.12577 to 0.12417, saving model to Results/MobilNET/model.hdf5\n","Epoch 20/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 9.2681e-04 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9563\n","\n","Epoch 00020: val_loss did not improve from 0.12417\n","Epoch 21/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9563\n","\n","Epoch 00021: val_loss did not improve from 0.12417\n","Epoch 22/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 5.6326e-04 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9589\n","\n","Epoch 00022: val_loss did not improve from 0.12417\n","Epoch 23/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 5.6310e-04 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9589\n","\n","Epoch 00023: val_loss did not improve from 0.12417\n","Epoch 24/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 8.0031e-04 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9563\n","\n","Epoch 00024: val_loss did not improve from 0.12417\n","Epoch 25/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 4.8073e-04 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9614\n","\n","Epoch 00025: val_loss did not improve from 0.12417\n","Epoch 26/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 6.4130e-04 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9589\n","\n","Epoch 00026: val_loss did not improve from 0.12417\n","Epoch 27/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 3.7761e-04 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 0.9614\n","\n","Epoch 00027: val_loss did not improve from 0.12417\n","Epoch 28/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 3.2635e-04 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9614\n","\n","Epoch 00028: val_loss did not improve from 0.12417\n","Epoch 29/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 2.8804e-04 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9614\n","\n","Epoch 00029: val_loss did not improve from 0.12417\n","Epoch 30/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 5.5282e-04 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9614\n","\n","Epoch 00030: val_loss did not improve from 0.12417\n","Epoch 31/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 2.4913e-04 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9614\n","\n","Epoch 00031: val_loss did not improve from 0.12417\n","Epoch 32/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 2.5704e-04 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9589\n","\n","Epoch 00032: val_loss did not improve from 0.12417\n","Epoch 33/50\n","3494/3494 [==============================] - 32s 9ms/step - loss: 3.4035e-04 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9614\n","\n","Epoch 00033: val_loss did not improve from 0.12417\n","Epoch 34/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 3.0181e-04 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9589\n","\n","Epoch 00034: val_loss did not improve from 0.12417\n","Epoch 35/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 2.2069e-04 - accuracy: 1.0000 - val_loss: 0.1317 - val_accuracy: 0.9614\n","\n","Epoch 00035: val_loss did not improve from 0.12417\n","Epoch 36/50\n","3494/3494 [==============================] - 32s 9ms/step - loss: 2.1568e-04 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9614\n","\n","Epoch 00036: val_loss did not improve from 0.12417\n","Epoch 37/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 2.0630e-04 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9589\n","\n","Epoch 00037: val_loss did not improve from 0.12417\n","Epoch 38/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 4.2246e-04 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9563\n","\n","Epoch 00038: val_loss did not improve from 0.12417\n","Epoch 39/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 2.5490e-04 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9563\n","\n","Epoch 00039: val_loss did not improve from 0.12417\n","Epoch 40/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 1.9559e-04 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9589\n","\n","Epoch 00040: val_loss did not improve from 0.12417\n","Epoch 41/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 2.0873e-04 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9589\n","\n","Epoch 00041: val_loss did not improve from 0.12417\n","Epoch 42/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 1.2782e-04 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9589\n","\n","Epoch 00042: val_loss did not improve from 0.12417\n","Epoch 43/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 2.0062e-04 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9589\n","\n","Epoch 00043: val_loss did not improve from 0.12417\n","Epoch 44/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 4.2775e-04 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.9537\n","\n","Epoch 00044: val_loss did not improve from 0.12417\n","Epoch 45/50\n","3494/3494 [==============================] - 32s 9ms/step - loss: 2.1080e-04 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9614\n","\n","Epoch 00045: val_loss did not improve from 0.12417\n","Epoch 46/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 1.9479e-04 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9563\n","\n","Epoch 00046: val_loss did not improve from 0.12417\n","Epoch 47/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 1.2876e-04 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9563\n","\n","Epoch 00047: val_loss did not improve from 0.12417\n","Epoch 48/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 1.8536e-04 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9537\n","\n","Epoch 00048: val_loss did not improve from 0.12417\n","Epoch 49/50\n","3494/3494 [==============================] - 31s 9ms/step - loss: 1.4133e-04 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9614\n","\n","Epoch 00049: val_loss did not improve from 0.12417\n","Epoch 50/50\n","3494/3494 [==============================] - 32s 9ms/step - loss: 1.3139e-04 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9537\n","\n","Epoch 00050: val_loss did not improve from 0.12417\n","[[582  47]\n"," [ 23 319]]\n","              precision    recall  f1-score   support\n","\n","           0     0.9620    0.9253    0.9433       629\n","           1     0.8716    0.9327    0.9011       342\n","\n","    accuracy                         0.9279       971\n","   macro avg     0.9168    0.9290    0.9222       971\n","weighted avg     0.9301    0.9279    0.9284       971\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eiQ0uykFe7HO","colab_type":"text"},"source":["# ResNET"]},{"cell_type":"code","metadata":{"id":"N-PgsNObRTrx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592957756051,"user_tz":-180,"elapsed":3492244,"user":{"displayName":"Murat UÇAR","photoUrl":"","userId":"15135126161682441538"}},"outputId":"84291004-6634-4ee4-cb2f-f49a2d90ce01"},"source":["from keras.applications.resnet  import ResNet50\n","from keras.applications.resnet import preprocess_input\n","\n","os.chdir(mainFolder)\n","\n","x_train = preprocess_input(FileRead(imageFolder,trainFiles,(224,224)))\n","x_test = preprocess_input(FileRead(imageFolder,testFiles,(224,224)))\n","x_val = preprocess_input(FileRead(imageFolder,validationFiles,(224,224)))\n","\n","resultFolder =\"Results/ResNET\" \n","\n","\n","\n","checkpoint = ModelCheckpoint(os.path.join(resultFolder,\"model.hdf5\"), monitor='val_loss', verbose=1,\n","    save_best_only=True, mode='auto', period=1)\n","\n","base_model = ResNet50(weights='imagenet',include_top=False)\n","\n","# add a global spatial average pooling layer\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","#x = Dense(1024, activation='relu')(x)\n","predictions = Dense(2, activation='softmax')(x)\n","\n","# this is the model we will train\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","for layer in model.layers:\n","    layer.trainable = True  \n","\n","adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n","model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","history = model.fit(x_train,y_train,\n","                    batch_size=32,\n","                    validation_data=(x_val, y_val),\n","                     verbose=1,epochs=50,\n","                    callbacks=[checkpoint]\n","                    )\n","\n","model = load_model(os.path.join(resultFolder,\"model.hdf5\"))\n","y_head = model.predict(x_test)\n","clfReport = classification_report(np.argmax(y_test,axis=1),np.argmax(y_head,axis=1) ,digits=4)\n","cnfMatris = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_head,axis=1))\n","print(cnfMatris)\n","print(clfReport)\n","\n","np.save(os.path.join(resultFolder,\"confMatris.npy\"),cnfMatris)\n","with open(os.path.join(resultFolder,'trainHistoryDict'), 'wb') as file_pi:\n","        pickle.dump(history.history, file_pi)\n","with open(os.path.join(resultFolder,'clfReport'), 'wb') as file_pi:\n","        pickle.dump(clfReport, file_pi)        \n","np.save(os.path.join(resultFolder,\"preds.npy\"),y_head)\n","np.save(os.path.join(resultFolder,\"y_test.npy\"),y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94773248/94765736 [==============================] - 8s 0us/step\n","Train on 3494 samples, validate on 389 samples\n","Epoch 1/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.4576 - accuracy: 0.8263 - val_loss: 33.3249 - val_accuracy: 0.3548\n","\n","Epoch 00001: val_loss improved from inf to 33.32488, saving model to Results/ResNET/model.hdf5\n","Epoch 2/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.2567 - accuracy: 0.8947 - val_loss: 1.7083 - val_accuracy: 0.7352\n","\n","Epoch 00002: val_loss improved from 33.32488 to 1.70833, saving model to Results/ResNET/model.hdf5\n","Epoch 3/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.1912 - accuracy: 0.9230 - val_loss: 0.3546 - val_accuracy: 0.8638\n","\n","Epoch 00003: val_loss improved from 1.70833 to 0.35456, saving model to Results/ResNET/model.hdf5\n","Epoch 4/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.1553 - accuracy: 0.9359 - val_loss: 1.0439 - val_accuracy: 0.7789\n","\n","Epoch 00004: val_loss did not improve from 0.35456\n","Epoch 5/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.1366 - accuracy: 0.9459 - val_loss: 0.3550 - val_accuracy: 0.8535\n","\n","Epoch 00005: val_loss did not improve from 0.35456\n","Epoch 6/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.1040 - accuracy: 0.9614 - val_loss: 0.3950 - val_accuracy: 0.8740\n","\n","Epoch 00006: val_loss did not improve from 0.35456\n","Epoch 7/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0691 - accuracy: 0.9745 - val_loss: 0.1223 - val_accuracy: 0.9486\n","\n","Epoch 00007: val_loss improved from 0.35456 to 0.12228, saving model to Results/ResNET/model.hdf5\n","Epoch 8/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0556 - accuracy: 0.9794 - val_loss: 0.3630 - val_accuracy: 0.8972\n","\n","Epoch 00008: val_loss did not improve from 0.12228\n","Epoch 9/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0967 - accuracy: 0.9631 - val_loss: 0.7492 - val_accuracy: 0.8201\n","\n","Epoch 00009: val_loss did not improve from 0.12228\n","Epoch 10/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0620 - accuracy: 0.9782 - val_loss: 0.1546 - val_accuracy: 0.9332\n","\n","Epoch 00010: val_loss did not improve from 0.12228\n","Epoch 11/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0609 - accuracy: 0.9780 - val_loss: 0.2331 - val_accuracy: 0.9306\n","\n","Epoch 00011: val_loss did not improve from 0.12228\n","Epoch 12/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0480 - accuracy: 0.9825 - val_loss: 0.1968 - val_accuracy: 0.9486\n","\n","Epoch 00012: val_loss did not improve from 0.12228\n","Epoch 13/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0505 - accuracy: 0.9848 - val_loss: 0.1823 - val_accuracy: 0.9434\n","\n","Epoch 00013: val_loss did not improve from 0.12228\n","Epoch 14/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0319 - accuracy: 0.9874 - val_loss: 0.1520 - val_accuracy: 0.9332\n","\n","Epoch 00014: val_loss did not improve from 0.12228\n","Epoch 15/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0214 - accuracy: 0.9908 - val_loss: 0.1031 - val_accuracy: 0.9589\n","\n","Epoch 00015: val_loss improved from 0.12228 to 0.10315, saving model to Results/ResNET/model.hdf5\n","Epoch 16/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0230 - accuracy: 0.9917 - val_loss: 0.1715 - val_accuracy: 0.9537\n","\n","Epoch 00016: val_loss did not improve from 0.10315\n","Epoch 17/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0375 - accuracy: 0.9880 - val_loss: 0.2979 - val_accuracy: 0.9280\n","\n","Epoch 00017: val_loss did not improve from 0.10315\n","Epoch 18/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0338 - accuracy: 0.9880 - val_loss: 0.1878 - val_accuracy: 0.9383\n","\n","Epoch 00018: val_loss did not improve from 0.10315\n","Epoch 19/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0153 - accuracy: 0.9943 - val_loss: 0.1491 - val_accuracy: 0.9537\n","\n","Epoch 00019: val_loss did not improve from 0.10315\n","Epoch 20/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 0.2016 - val_accuracy: 0.9486\n","\n","Epoch 00020: val_loss did not improve from 0.10315\n","Epoch 21/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.1621 - val_accuracy: 0.9640\n","\n","Epoch 00021: val_loss did not improve from 0.10315\n","Epoch 22/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.1893 - val_accuracy: 0.9332\n","\n","Epoch 00022: val_loss did not improve from 0.10315\n","Epoch 23/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0255 - accuracy: 0.9914 - val_loss: 0.3229 - val_accuracy: 0.9434\n","\n","Epoch 00023: val_loss did not improve from 0.10315\n","Epoch 24/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0816 - accuracy: 0.9708 - val_loss: 0.8060 - val_accuracy: 0.8380\n","\n","Epoch 00024: val_loss did not improve from 0.10315\n","Epoch 25/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0303 - accuracy: 0.9903 - val_loss: 0.1221 - val_accuracy: 0.9589\n","\n","Epoch 00025: val_loss did not improve from 0.10315\n","Epoch 26/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.1216 - val_accuracy: 0.9563\n","\n","Epoch 00026: val_loss did not improve from 0.10315\n","Epoch 27/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.1463 - accuracy: 0.9522 - val_loss: 0.4079 - val_accuracy: 0.8997\n","\n","Epoch 00027: val_loss did not improve from 0.10315\n","Epoch 28/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0598 - accuracy: 0.9803 - val_loss: 0.0908 - val_accuracy: 0.9614\n","\n","Epoch 00028: val_loss improved from 0.10315 to 0.09080, saving model to Results/ResNET/model.hdf5\n","Epoch 29/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0738 - val_accuracy: 0.9820\n","\n","Epoch 00029: val_loss improved from 0.09080 to 0.07382, saving model to Results/ResNET/model.hdf5\n","Epoch 30/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.1594 - val_accuracy: 0.9537\n","\n","Epoch 00030: val_loss did not improve from 0.07382\n","Epoch 31/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0986 - val_accuracy: 0.9717\n","\n","Epoch 00031: val_loss did not improve from 0.07382\n","Epoch 32/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.1020 - val_accuracy: 0.9743\n","\n","Epoch 00032: val_loss did not improve from 0.07382\n","Epoch 33/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0162 - accuracy: 0.9940 - val_loss: 0.0849 - val_accuracy: 0.9666\n","\n","Epoch 00033: val_loss did not improve from 0.07382\n","Epoch 34/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.1060 - val_accuracy: 0.9666\n","\n","Epoch 00034: val_loss did not improve from 0.07382\n","Epoch 35/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.1540 - accuracy: 0.9448 - val_loss: 0.5108 - val_accuracy: 0.9254\n","\n","Epoch 00035: val_loss did not improve from 0.07382\n","Epoch 36/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0501 - accuracy: 0.9797 - val_loss: 0.2077 - val_accuracy: 0.9486\n","\n","Epoch 00036: val_loss did not improve from 0.07382\n","Epoch 37/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0334 - accuracy: 0.9863 - val_loss: 0.1266 - val_accuracy: 0.9563\n","\n","Epoch 00037: val_loss did not improve from 0.07382\n","Epoch 38/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.1088 - val_accuracy: 0.9640\n","\n","Epoch 00038: val_loss did not improve from 0.07382\n","Epoch 39/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0875 - val_accuracy: 0.9717\n","\n","Epoch 00039: val_loss did not improve from 0.07382\n","Epoch 40/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9769\n","\n","Epoch 00040: val_loss did not improve from 0.07382\n","Epoch 41/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0905 - val_accuracy: 0.9820\n","\n","Epoch 00041: val_loss did not improve from 0.07382\n","Epoch 42/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0186 - accuracy: 0.9920 - val_loss: 0.1088 - val_accuracy: 0.9614\n","\n","Epoch 00042: val_loss did not improve from 0.07382\n","Epoch 43/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0510 - accuracy: 0.9834 - val_loss: 0.8244 - val_accuracy: 0.8817\n","\n","Epoch 00043: val_loss did not improve from 0.07382\n","Epoch 44/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0180 - accuracy: 0.9937 - val_loss: 0.2129 - val_accuracy: 0.9460\n","\n","Epoch 00044: val_loss did not improve from 0.07382\n","Epoch 45/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0560 - accuracy: 0.9817 - val_loss: 0.1417 - val_accuracy: 0.9537\n","\n","Epoch 00045: val_loss did not improve from 0.07382\n","Epoch 46/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0966 - val_accuracy: 0.9846\n","\n","Epoch 00046: val_loss did not improve from 0.07382\n","Epoch 47/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1143 - val_accuracy: 0.9692\n","\n","Epoch 00047: val_loss did not improve from 0.07382\n","Epoch 48/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.1615 - val_accuracy: 0.9563\n","\n","Epoch 00048: val_loss did not improve from 0.07382\n","Epoch 49/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.1406 - val_accuracy: 0.9589\n","\n","Epoch 00049: val_loss did not improve from 0.07382\n","Epoch 50/50\n","3494/3494 [==============================] - 64s 18ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.1413 - val_accuracy: 0.9666\n","\n","Epoch 00050: val_loss did not improve from 0.07382\n","[[602  27]\n"," [ 27 315]]\n","              precision    recall  f1-score   support\n","\n","           0     0.9571    0.9571    0.9571       629\n","           1     0.9211    0.9211    0.9211       342\n","\n","    accuracy                         0.9444       971\n","   macro avg     0.9391    0.9391    0.9391       971\n","weighted avg     0.9444    0.9444    0.9444       971\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uO3EWOlgmAlV","colab_type":"text"},"source":["# Inception V3"]},{"cell_type":"code","metadata":{"id":"5iuGrafUl5A_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592962147511,"user_tz":-180,"elapsed":3961974,"user":{"displayName":"Murat UÇAR","photoUrl":"","userId":"15135126161682441538"}},"outputId":"5aef2f2a-0f71-449d-ac06-04a5e12011d4"},"source":["from keras.applications.inception_v3  import InceptionV3\n","from keras.applications.inception_v3 import preprocess_input\n","\n","os.chdir(mainFolder)\n","\n","x_train = preprocess_input(FileRead(imageFolder,trainFiles,(299,299)))\n","x_test = preprocess_input(FileRead(imageFolder,testFiles,(299,299)))\n","x_val = preprocess_input(FileRead(imageFolder,validationFiles,(299,299)))\n","\n","resultFolder =\"Results/InceptionV3\" \n","\n","checkpoint = ModelCheckpoint(os.path.join(resultFolder,\"model.hdf5\"), monitor='val_loss', verbose=1,\n","    save_best_only=True, mode='auto', period=1)\n","\n","base_model = InceptionV3(weights='imagenet',include_top=False)\n","\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","predictions = Dense(2, activation='softmax')(x)\n","\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","for layer in model.layers:\n","    layer.trainable = True  \n","\n","adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n","model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","history = model.fit(x_train,y_train,\n","                    batch_size=32,\n","                    validation_data=(x_val, y_val),\n","                     verbose=1,epochs=50,\n","                    callbacks=[checkpoint]\n","                    )\n","\n","model = load_model(os.path.join(resultFolder,\"model.hdf5\"))\n","y_head = model.predict(x_test)\n","clfReport = classification_report(np.argmax(y_test,axis=1),np.argmax(y_head,axis=1) ,digits=4)\n","cnfMatris = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(y_head,axis=1))\n","print(cnfMatris)\n","print(clfReport)\n","\n","np.save(os.path.join(resultFolder,\"confMatris.npy\"),cnfMatris)\n","with open(os.path.join(resultFolder,'trainHistoryDict'), 'wb') as file_pi:\n","        pickle.dump(history.history, file_pi)\n","with open(os.path.join(resultFolder,'clfReport'), 'wb') as file_pi:\n","        pickle.dump(clfReport, file_pi)        \n","np.save(os.path.join(resultFolder,\"preds.npy\"),y_head)\n","np.save(os.path.join(resultFolder,\"y_test.npy\"),y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 3494 samples, validate on 389 samples\n","Epoch 1/50\n","3494/3494 [==============================] - 96s 28ms/step - loss: 0.3538 - accuracy: 0.8457 - val_loss: 4.7662 - val_accuracy: 0.3805\n","\n","Epoch 00001: val_loss improved from inf to 4.76618, saving model to Results/InceptionV3/model.hdf5\n","Epoch 2/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.1915 - accuracy: 0.9282 - val_loss: 1.3850 - val_accuracy: 0.6607\n","\n","Epoch 00002: val_loss improved from 4.76618 to 1.38496, saving model to Results/InceptionV3/model.hdf5\n","Epoch 3/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.1397 - accuracy: 0.9471 - val_loss: 0.2673 - val_accuracy: 0.9100\n","\n","Epoch 00003: val_loss improved from 1.38496 to 0.26727, saving model to Results/InceptionV3/model.hdf5\n","Epoch 4/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.1238 - accuracy: 0.9508 - val_loss: 0.2884 - val_accuracy: 0.8972\n","\n","Epoch 00004: val_loss did not improve from 0.26727\n","Epoch 5/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0639 - accuracy: 0.9774 - val_loss: 0.3335 - val_accuracy: 0.9126\n","\n","Epoch 00005: val_loss did not improve from 0.26727\n","Epoch 6/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0760 - accuracy: 0.9745 - val_loss: 0.2371 - val_accuracy: 0.9306\n","\n","Epoch 00006: val_loss improved from 0.26727 to 0.23708, saving model to Results/InceptionV3/model.hdf5\n","Epoch 7/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0853 - accuracy: 0.9694 - val_loss: 0.5626 - val_accuracy: 0.8535\n","\n","Epoch 00007: val_loss did not improve from 0.23708\n","Epoch 8/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0677 - accuracy: 0.9774 - val_loss: 0.7044 - val_accuracy: 0.7815\n","\n","Epoch 00008: val_loss did not improve from 0.23708\n","Epoch 9/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0330 - accuracy: 0.9888 - val_loss: 0.1537 - val_accuracy: 0.9409\n","\n","Epoch 00009: val_loss improved from 0.23708 to 0.15365, saving model to Results/InceptionV3/model.hdf5\n","Epoch 10/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0451 - accuracy: 0.9834 - val_loss: 0.3193 - val_accuracy: 0.9177\n","\n","Epoch 00010: val_loss did not improve from 0.15365\n","Epoch 11/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0649 - accuracy: 0.9762 - val_loss: 2.2402 - val_accuracy: 0.5964\n","\n","Epoch 00011: val_loss did not improve from 0.15365\n","Epoch 12/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0808 - accuracy: 0.9725 - val_loss: 0.2041 - val_accuracy: 0.9460\n","\n","Epoch 00012: val_loss did not improve from 0.15365\n","Epoch 13/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0756 - accuracy: 0.9731 - val_loss: 0.1841 - val_accuracy: 0.9434\n","\n","Epoch 00013: val_loss did not improve from 0.15365\n","Epoch 14/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0422 - accuracy: 0.9840 - val_loss: 0.1656 - val_accuracy: 0.9486\n","\n","Epoch 00014: val_loss did not improve from 0.15365\n","Epoch 15/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.1468 - val_accuracy: 0.9512\n","\n","Epoch 00015: val_loss improved from 0.15365 to 0.14685, saving model to Results/InceptionV3/model.hdf5\n","Epoch 16/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.1479 - accuracy: 0.9465 - val_loss: 0.7538 - val_accuracy: 0.8638\n","\n","Epoch 00016: val_loss did not improve from 0.14685\n","Epoch 17/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.1284 - accuracy: 0.9473 - val_loss: 0.2052 - val_accuracy: 0.9357\n","\n","Epoch 00017: val_loss did not improve from 0.14685\n","Epoch 18/50\n","3494/3494 [==============================] - 73s 21ms/step - loss: 0.0483 - accuracy: 0.9820 - val_loss: 0.1482 - val_accuracy: 0.9434\n","\n","Epoch 00018: val_loss did not improve from 0.14685\n","Epoch 19/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0240 - accuracy: 0.9926 - val_loss: 0.3707 - val_accuracy: 0.8843\n","\n","Epoch 00019: val_loss did not improve from 0.14685\n","Epoch 20/50\n","3494/3494 [==============================] - 73s 21ms/step - loss: 0.0349 - accuracy: 0.9860 - val_loss: 0.2809 - val_accuracy: 0.9280\n","\n","Epoch 00020: val_loss did not improve from 0.14685\n","Epoch 21/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.1000 - accuracy: 0.9657 - val_loss: 0.6338 - val_accuracy: 0.8252\n","\n","Epoch 00021: val_loss did not improve from 0.14685\n","Epoch 22/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.1451 - val_accuracy: 0.9537\n","\n","Epoch 00022: val_loss improved from 0.14685 to 0.14510, saving model to Results/InceptionV3/model.hdf5\n","Epoch 23/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0269 - accuracy: 0.9903 - val_loss: 0.1274 - val_accuracy: 0.9614\n","\n","Epoch 00023: val_loss improved from 0.14510 to 0.12740, saving model to Results/InceptionV3/model.hdf5\n","Epoch 24/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.1450 - val_accuracy: 0.9512\n","\n","Epoch 00024: val_loss did not improve from 0.12740\n","Epoch 25/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0346 - accuracy: 0.9877 - val_loss: 0.1326 - val_accuracy: 0.9666\n","\n","Epoch 00025: val_loss did not improve from 0.12740\n","Epoch 26/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.1132 - accuracy: 0.9565 - val_loss: 0.1603 - val_accuracy: 0.9460\n","\n","Epoch 00026: val_loss did not improve from 0.12740\n","Epoch 27/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0343 - accuracy: 0.9874 - val_loss: 0.1728 - val_accuracy: 0.9537\n","\n","Epoch 00027: val_loss did not improve from 0.12740\n","Epoch 28/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.1575 - val_accuracy: 0.9512\n","\n","Epoch 00028: val_loss did not improve from 0.12740\n","Epoch 29/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.1343 - val_accuracy: 0.9640\n","\n","Epoch 00029: val_loss did not improve from 0.12740\n","Epoch 30/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0856 - val_accuracy: 0.9743\n","\n","Epoch 00030: val_loss improved from 0.12740 to 0.08556, saving model to Results/InceptionV3/model.hdf5\n","Epoch 31/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9692\n","\n","Epoch 00031: val_loss did not improve from 0.08556\n","Epoch 32/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 7.7017e-04 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9717\n","\n","Epoch 00032: val_loss did not improve from 0.08556\n","Epoch 33/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 4.6476e-04 - accuracy: 1.0000 - val_loss: 0.1165 - val_accuracy: 0.9769\n","\n","Epoch 00033: val_loss did not improve from 0.08556\n","Epoch 34/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1005 - val_accuracy: 0.9794\n","\n","Epoch 00034: val_loss did not improve from 0.08556\n","Epoch 35/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9794\n","\n","Epoch 00035: val_loss improved from 0.08556 to 0.07881, saving model to Results/InceptionV3/model.hdf5\n","Epoch 36/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.1176 - val_accuracy: 0.9846\n","\n","Epoch 00036: val_loss did not improve from 0.07881\n","Epoch 37/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0237 - accuracy: 0.9914 - val_loss: 0.2746 - val_accuracy: 0.9177\n","\n","Epoch 00037: val_loss did not improve from 0.07881\n","Epoch 38/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0648 - accuracy: 0.9780 - val_loss: 0.9340 - val_accuracy: 0.8380\n","\n","Epoch 00038: val_loss did not improve from 0.07881\n","Epoch 39/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0318 - accuracy: 0.9917 - val_loss: 0.1588 - val_accuracy: 0.9563\n","\n","Epoch 00039: val_loss did not improve from 0.07881\n","Epoch 40/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.0868 - val_accuracy: 0.9743\n","\n","Epoch 00040: val_loss did not improve from 0.07881\n","Epoch 41/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.1075 - val_accuracy: 0.9614\n","\n","Epoch 00041: val_loss did not improve from 0.07881\n","Epoch 42/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.1576 - accuracy: 0.9445 - val_loss: 0.2517 - val_accuracy: 0.9460\n","\n","Epoch 00042: val_loss did not improve from 0.07881\n","Epoch 43/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0616 - accuracy: 0.9774 - val_loss: 0.2186 - val_accuracy: 0.9332\n","\n","Epoch 00043: val_loss did not improve from 0.07881\n","Epoch 44/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.0857 - val_accuracy: 0.9743\n","\n","Epoch 00044: val_loss did not improve from 0.07881\n","Epoch 45/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0851 - val_accuracy: 0.9743\n","\n","Epoch 00045: val_loss did not improve from 0.07881\n","Epoch 46/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0818 - val_accuracy: 0.9717\n","\n","Epoch 00046: val_loss did not improve from 0.07881\n","Epoch 47/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1492 - val_accuracy: 0.9614\n","\n","Epoch 00047: val_loss did not improve from 0.07881\n","Epoch 48/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1584 - val_accuracy: 0.9614\n","\n","Epoch 00048: val_loss did not improve from 0.07881\n","Epoch 49/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.1848 - val_accuracy: 0.9589\n","\n","Epoch 00049: val_loss did not improve from 0.07881\n","Epoch 50/50\n","3494/3494 [==============================] - 74s 21ms/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 0.3002 - val_accuracy: 0.9177\n","\n","Epoch 00050: val_loss did not improve from 0.07881\n","[[599  30]\n"," [ 18 324]]\n","              precision    recall  f1-score   support\n","\n","           0     0.9708    0.9523    0.9615       629\n","           1     0.9153    0.9474    0.9310       342\n","\n","    accuracy                         0.9506       971\n","   macro avg     0.9430    0.9498    0.9463       971\n","weighted avg     0.9513    0.9506    0.9508       971\n","\n"],"name":"stdout"}]}]}